\section{Graph and network optimization}

\subsection{Graph reachability problem}

Given a graph $G = (N,A)$ and a node $s$, find all nodes that are reachable from $s$.

Efficient algorithms use queues to keep track of previously expanded nodes; different objectives are pursued based on the queue type, each with its complexities.

\subsection{Minimum spanning tree}

Given a graph $G = (N,E)$, with each edge having a cost $c_e \in \mathbb{R}$, find a spanning tree $G_T = (N,T)$ with minimum total cost.
Being $X$ the set of all the spanning trees of $G$, the objective is to find

$$ \min_{T \in X} \sum_{e \in T} c_e $$

that may not be a easy task being the number of spanning trees $2^{n-2}$, with $n$ the number of nodes of the graph.

\subsubsection{Kruskal method}

Firstly, the arcs list is ordered from the least costly to the most costly.
Then, one arc after the other, they are popped and added to the graph.
If adding an arc would create a cycle, it is skipped.
In the end, what does remain is the minimum spanning tree.

\subsubsection{Prim's algorithm}

The spanning tree is built iteratively, starting from an initial tree $(S,T)$, where $S={u}$ and $T=\emptyset$.

At each iteration, the edge with the lower cost (among the unchosen edges of the cut $S$) is added to $T$, and the node it connects to $S$.

The complexity of the algorithm is $O(nm)$, being $n$ the number of nodes and $m$ the number of edges.

This algorithm is exact, since it always provides an optimal solution.
It is also greedy, since it look for the local minima iteratively, without reconsidering previous choices.

\newpar
A variance of the Prim's algorithm with complexity $O(n^2)$ can be achieved by associating each node with another.
Each node $i$ is assigned with another node $j$, that is either the predecessor (if $i \in S$), or the one in the spanning tree with which it has minimum cost ($\mathrm{argmin}_{i,j} c_{ij}$).

This way, with each iteration, it is faster to choose the node with minimum cost that connects to the newly expanded node.

\subsection{Dijkstra's algorithm}

Dijkstra's algorithm can be used to find the shortest path from a node to all other nodes of the graph.

Each node is assigned a label storing the cost of the current shortest path found, along with the predecessor in that path.
At each iteration nodes in the frontier are expanded, and if the new path for the neighboring is shorter than their previous, the labels of the are updated.

If all $m$ arcs are scanned the complexity is $O(mn)$, but if labels are appropriately updated complexity becomes $O(n^2)$.
Dijkstra's algorithm is exact, meaning it always provides an optimal solution.
It does not work with negative cost arcs.

The tree made from the set of short paths for a node $s$ is called the arborescence rooted at $s$.

\subsection{Floyd-Warshall algorithm}

This algorithm can be used when the graph contains paths with negative costs.

The graph is to be described via a matrix $D$, in which each cell is the cost between the row and column nodes.
Along with $D$, define a matrix $P$ which, in the end, $p_{ij}$ is the predecessor of $j$ in the shortest path from $i$ to $j$.

$$
D=
\begin{bmatrix}
    0 & 2 & \infty & 1 \\
    \infty & 0 & 3 & 3 \\
    \infty & 0 & 2 & \infty \\
    \infty & -5 & 5 & \infty
\end{bmatrix}
\hspace{2.5cm}
P=
\begin{bmatrix}
    1 & 1 & 1 & 1 \\
    2 & 2 & 2 & 2 \\
    3 & 3 & 3 & 3 \\
    4 & 4 & 4 & 4
\end{bmatrix}
$$

Then, for each $u = 1, \dots, n$, if $d_{iu} + d_{uj} < d_{ij}$, then $d_{ij} = d_{iu} + d_{uj}$.
If the path cost is updated, then the corresponding element of the $P$ matrix is updated to $u$.

The Floyd-Warshall algorithm is exact, with complexity $O(n^3)$, being $n$ the number of nodes.

\subsection{Topological ordering method}

A DAG (directed acyclic graph) can be rearranged so that, for every path $(i, j)$, an order $i < j$ is defined.

Each "layer" of the topological ordered graph is found iteratively, starting from a node which has no incoming edge.
With each iteration, fill the following layer with the nodes directly reachable from the current.

Complexity is $O(n+m)$, since each node and each arc is considered once.

\subsection{Dynamic programming}

Dynamic programming is a technique for which an optimal solution is found by resolving a set of recursive equations.
It can be applied to decision problems that satisfy the optimality principle, stating that if a path from node $1$ to $j$ is the shortest, than the path from $1$ to $i$, where $i$ is the predecessor of $j$ in the path, is also optimal.

\subsubsection{Shorter path in DAGs}

Let $L_n$ be the cost of the path between node $1$ and $n$.
If the objective is to find the minimum-cost path from $1$ to $i$, then the problem becomes to minimize the value of $$L_{j} + c_{ji}$$ where $j$ is the predecessor of $i$ and $c_{ji}$ is the cost between $j$ and $i$.

For example, the set of recursive equations that describe the problem may be

\begin{align*}
    \textrm{pred}_i = 1 &, \quad L_1 = 0 \\
    \textrm{pred}_i = 1 &, \quad L_2 = L_1 + c_{12} = 4 \\
    \textrm{pred}_i = 1 &, \quad L_3 = L_1 + c_{13} = 2 \\
    \textrm{pred}_i = 3 &, \quad L_4 = \min_{i=1,2,3}\{L_i + c_{i4}\} = \min\{0+5, 4+2, 2+1\} = 3
\end{align*}

where, with each iteration over the formulae, the cost and predecessor of each node is updated until the formula for the final node has no dependencies left over.

\subsection{Project planning}

A project is a set of activities each with its duration.

Activities may have a precedence constraint, for example $A_i \propto A_j$.
In those cases, the starting node of $A_j$ must appear after the ending node of $A_i$.

Between activity arches, dummy arcs can be added to symbolize dependencies.
Artificial nodes and arcs may also be added in order to obtain a single initial and final node.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[state/.style={circle, draw, minimum width=1mm}]
        \node[state] (A) {};
        \node[left = 0.1cm of A] {s};
        \node[state] (B) [right = of A] {};
        \node[state] (C) [above right = of B] {};
        \node[state] (D) [below right = of B] {};
        \node[state] (E) [below right = of C] {};
        \node[right = 0.1cm of E] {t};
        \path (A) edge [->] node[above = 0.1cm] {A} (B);
        \path (B) edge [->] node[above = 0.1cm] {B} (C);
        \path (B) edge [->] node[below = 0.1cm] {C} (D);
        \path (C) edge [->, dashed] (D);
        \path (C) edge [->] node[above = 0.1cm] {D} (E);
        \path (D) edge [->] node[below = 0.1cm] {E} (E);
    \end{tikzpicture}
\end{figure}

\subsubsection{Critical path method}

The CPM is used to determine a schedule, that is the set of activities that minimizes the total project duration, and the slack of each activity, that is maximum time an activity can be delayed.

After constructing the graph of activities in topological order, find

\begin{enumerate}
    \item the earliest time $T_{min}$ for each node with increasing indices,
    \item the latest time $T_{max}$ for each node with decreasing indices,
    \item the slack for each activity $\sigma_{ij} = T_{max, j} - T_{min, i} - d_{ij}$.
\end{enumerate}

A critical path is one that has slack equal to zero.

\subsection{Network flow}

A network is a directed and connected graph, that contains both a source (a node with only outgoing arcs) and a sink (a node with only ingoing arcs).

Each arc of the graph can be assigned with a value in order to produce a feasible flow.
This values must satisfy both the capacity constraint, meaning that the value must be less than the arc original cost, and the flow balance constraint, stating that the sum of the ingoing arc values for a node must be equal to the outgoings.

The value of flow is the sum of outgoing values from the source node.
An arc is saturated if the assigned value is the same as the cost, or else it is empty if it is zero.

A cut of the graph has a capacity equal to the sum of the outgoing arcs costs, and given a feasible flow, this has a value through the cut equal to the difference between ingoing and outgoing arc values.

Given a feasible flow, each cut $S$ of the graph has a value $\phi$ of the flow that is equal to the one of the source node: $\phi(S) = \phi(\{s\})$.
Furthermore, the value of the flow is always less than the capacity of the cut: $\phi(S) \le k(S)$.
If $\phi(S) = k(S)$ then the the feasible flow $\underline{x}$ is of maximum value and the cut $\delta(S)$ is of minimum capacity.
From here, two main problem arise: the primal problem consists of finding a feasible flow of maximum value; the dual problem consists of finding a cut of minimum capacity.

\subsubsection{Ford-Fulkerson algorithm}

The Ford-Fulkerson algorithm is a method for computing the maximum flow in a flow network. It is based on the idea of finding augmenting paths and increasing the flow along these paths until no more augmenting paths can be found.

Firstly, initialize the graph by setting all edge flows to zero.
Then, with each iteration, find a path from the source to the sink where the available capacity is greater than the current flow and increase the flow along this path by the smallest available capacity on the path (the bottleneck).
After augmenting the flow, update the residual capacities of the edges.
This process is to be repeated until no more augmenting path can be found.

This algorithm is non-greedy and exact.
The complexity is $O(m^2k_{max})$, where $m$ is the number of arcs and $k_{max}$ is the biggest capacity among all the arcs.
The algorithm can be inefficient in some cases, but when dealing with integer capacities it is possible to reduce complexity to be polynomial using other algorithm implementations.

\newpar
The theorem of strong duality derived from this algorithm tells that the value of a feasible flow of maximum value equals to the capacity of a cut of minimum capacity.
